{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f0edc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 300, 100)          1000000   \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 296, 128)          64128     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 148, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 144, 128)          82048     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 72, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                589888    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1736129 (6.62 MB)\n",
      "Trainable params: 1736129 (6.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "196/196 [==============================] - 16s 78ms/step - loss: 0.4826 - accuracy: 0.7124 - val_loss: 0.3140 - val_accuracy: 0.8637\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 0.2041 - accuracy: 0.9202 - val_loss: 0.2773 - val_accuracy: 0.8846\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.1251 - accuracy: 0.9537 - val_loss: 0.3461 - val_accuracy: 0.8765\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 0.0640 - accuracy: 0.9794 - val_loss: 0.4454 - val_accuracy: 0.8704\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 0.5955 - val_accuracy: 0.8652\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.6929 - val_accuracy: 0.8644\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 0.7684 - val_accuracy: 0.8703\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.8852 - val_accuracy: 0.8658\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.9710 - val_accuracy: 0.8655\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.8893 - val_accuracy: 0.8617\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.8893 - accuracy: 0.8617\n",
      "Test Loss: 0.8892743587493896\n",
      "Test Accuracy: 0.8617200255393982\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, Conv1D, MaxPooling1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load and preprocess the data\n",
    "num_words = 10000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
    "max_length = 300\n",
    "x_train = pad_sequences(x_train, maxlen=max_length)\n",
    "x_test = pad_sequences(x_test, maxlen=max_length)\n",
    "\n",
    "# Model architecture\n",
    "embedding_dim = 100\n",
    "filters = 128\n",
    "kernel_size = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_length))\n",
    "model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Test Loss:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dadd3273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n",
      "Review Sentiment: Negative\n",
      "Prediction Probability: 1.76796e-07\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(review_text):\n",
    "    # Tokenize and convert text to sequence\n",
    "    review_sequence = imdb.get_word_index()\n",
    "    words = review_text.lower().split()\n",
    "    review_sequence = [review_sequence[word] if word in review_sequence and review_sequence[word] < num_words else 2 for word in words]\n",
    "    review_sequence = pad_sequences([review_sequence], maxlen=max_length)\n",
    "    \n",
    "    # Predict sentiment\n",
    "    prediction = model.predict(review_sequence)[0][0]\n",
    "    \n",
    "    # Convert prediction to sentiment label\n",
    "    sentiment = \"Positive\" if prediction > 0.5 else \"Negative\"\n",
    "    \n",
    "    return sentiment, prediction\n",
    "\n",
    "# Test the prediction function\n",
    "review_text = \"This movie made it into one of my top 10 most awful movies. Horrible. <br /><br />There wasn't a continuous minute where there wasn't a fight with one monster or another. There was no chance for any character development, they were too busy running from one sword fight to another. I had no emotional attachment (except to the big bad machine that wanted to destroy them) <br /><br />Scenes were blatantly stolen from other movies, LOTR, Star Wars and Matrix. <br /><br />Examples<br /><br />>The ghost scene at the end was stolen from the final scene of the old Star Wars with Yoda, Obee One and Vader. <br /><br />>The spider machine in the beginning was exactly like Frodo being attacked by the spider in Return of the Kings. (Elijah Wood is the victim in both films) and wait......it hypnotizes (stings) its victim and wraps them up.....uh hello????<br /><br />>And the whole machine vs. humans theme WAS the Matrix..or Terminator.....<br /><br />There are more examples but why waste the time? And will someone tell me what was with the Nazi's?!?! Nazi's???? <br /><br />There was a juvenile story line rushed to a juvenile conclusion. The movie could not decide if it was a children's movie or an adult movie and wasn't much of either. <br /><br />Just awful. A real disappointment to say the least. Save your money.\"\n",
    "sentiment, prediction = predict_sentiment(review_text)\n",
    "print(\"Review Sentiment:\", sentiment)\n",
    "print(\"Prediction Probability:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ff448",
   "metadata": {},
   "source": [
    "This movie made it into one of my top 10 most awful movies. Horrible.\n",
    "\n",
    "There wasn't a continuous minute where there wasn't a fight with one monster or another. There was no chance for any character development, they were too busy running from one sword fight to another. I had no emotional attachment (except to the big bad machine that wanted to destroy them)\n",
    "\n",
    "Scenes were blatantly stolen from other movies, LOTR, Star Wars and Matrix.\n",
    "\n",
    "Examples\n",
    "\n",
    ">The ghost scene at the end was stolen from the final scene of the old Star Wars with Yoda, Obee One and Vader.\n",
    "\n",
    ">The spider machine in the beginning was exactly like Frodo being attacked by the spider in Return of the Kings. (Elijah Wood is the victim in both films) and wait......it hypnotizes (stings) its victim and wraps them up.....uh hello????\n",
    "\n",
    ">And the whole machine vs. humans theme WAS the Matrix..or Terminator.....\n",
    "\n",
    "There are more examples but why waste the time? And will someone tell me what was with the Nazi's?!?! Nazi's????\n",
    "\n",
    "There was a juvenile story line rushed to a juvenile conclusion. The movie could not decide if it was a children's movie or an adult movie and wasn't much of either.\n",
    "\n",
    "Just awful. A real disappointment to say the least. Save your money.\n",
    "\n",
    "sentiment : negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19e3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
